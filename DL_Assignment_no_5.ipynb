{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b1c6bae",
      "metadata": {
        "id": "0b1c6bae"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6e2378e",
      "metadata": {
        "id": "f6e2378e",
        "outputId": "a9621eb2-0ca6-44f7-ce47-c9d9bce3af0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7cd2fc2a9a50>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "970e30e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "970e30e2",
        "outputId": "1c4c2e5d-4dba-491d-8c7f-48b927df0c78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.6614,  0.2669,  0.0617,  0.6213, -0.4519]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ],
      "source": [
        "word_to_ix = {\"hello\": 0, \"world\": 1}\n",
        "embeds = nn.Embedding(2, 5)  # 2 words in vocab, 5 dimensional embeddings\n",
        "lookup_tensor = torch.tensor([word_to_ix[\"hello\"]], dtype=torch.long)\n",
        "hello_embed = embeds(lookup_tensor)\n",
        "print(hello_embed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ae61dd6",
      "metadata": {
        "id": "3ae61dd6"
      },
      "outputs": [],
      "source": [
        "CONTEXT_SIZE = 2\n",
        "EMBEDDING_DIM = 10\n",
        "# We will use Shakespeare Sonnet 2\n",
        "test_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
        "And dig deep trenches in thy beauty's field,\n",
        "Thy youth's proud livery so gazed on now,\n",
        "Will be a totter'd weed of small worth held:\n",
        "Then being asked, where all thy beauty lies,\n",
        "Where all the treasure of thy lusty days;\n",
        "To say, within thine own deep sunken eyes,\n",
        "Were an all-eating shame, and thriftless praise.\n",
        "How much more praise deserv'd thy beauty's use,\n",
        "If thou couldst answer 'This fair child of mine\n",
        "Shall sum my count, and make my old excuse,'\n",
        "Proving his beauty by succession thine!\n",
        "This were to be new made when thou art old,\n",
        "And see thy blood warm when thou feel'st it cold.\"\"\".split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c029f646",
      "metadata": {
        "id": "c029f646",
        "outputId": "624ef894-301c-4ff6-efe3-4284c5b3fff5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['When',\n",
              " 'forty',\n",
              " 'winters',\n",
              " 'shall',\n",
              " 'besiege',\n",
              " 'thy',\n",
              " 'brow,',\n",
              " 'And',\n",
              " 'dig',\n",
              " 'deep',\n",
              " 'trenches',\n",
              " 'in',\n",
              " 'thy',\n",
              " \"beauty's\",\n",
              " 'field,',\n",
              " 'Thy',\n",
              " \"youth's\",\n",
              " 'proud',\n",
              " 'livery',\n",
              " 'so',\n",
              " 'gazed',\n",
              " 'on',\n",
              " 'now,',\n",
              " 'Will',\n",
              " 'be',\n",
              " 'a',\n",
              " \"totter'd\",\n",
              " 'weed',\n",
              " 'of',\n",
              " 'small',\n",
              " 'worth',\n",
              " 'held:',\n",
              " 'Then',\n",
              " 'being',\n",
              " 'asked,',\n",
              " 'where',\n",
              " 'all',\n",
              " 'thy',\n",
              " 'beauty',\n",
              " 'lies,',\n",
              " 'Where',\n",
              " 'all',\n",
              " 'the',\n",
              " 'treasure',\n",
              " 'of',\n",
              " 'thy',\n",
              " 'lusty',\n",
              " 'days;',\n",
              " 'To',\n",
              " 'say,',\n",
              " 'within',\n",
              " 'thine',\n",
              " 'own',\n",
              " 'deep',\n",
              " 'sunken',\n",
              " 'eyes,',\n",
              " 'Were',\n",
              " 'an',\n",
              " 'all-eating',\n",
              " 'shame,',\n",
              " 'and',\n",
              " 'thriftless',\n",
              " 'praise.',\n",
              " 'How',\n",
              " 'much',\n",
              " 'more',\n",
              " 'praise',\n",
              " \"deserv'd\",\n",
              " 'thy',\n",
              " \"beauty's\",\n",
              " 'use,',\n",
              " 'If',\n",
              " 'thou',\n",
              " 'couldst',\n",
              " 'answer',\n",
              " \"'This\",\n",
              " 'fair',\n",
              " 'child',\n",
              " 'of',\n",
              " 'mine',\n",
              " 'Shall',\n",
              " 'sum',\n",
              " 'my',\n",
              " 'count,',\n",
              " 'and',\n",
              " 'make',\n",
              " 'my',\n",
              " 'old',\n",
              " \"excuse,'\",\n",
              " 'Proving',\n",
              " 'his',\n",
              " 'beauty',\n",
              " 'by',\n",
              " 'succession',\n",
              " 'thine!',\n",
              " 'This',\n",
              " 'were',\n",
              " 'to',\n",
              " 'be',\n",
              " 'new',\n",
              " 'made',\n",
              " 'when',\n",
              " 'thou',\n",
              " 'art',\n",
              " 'old,',\n",
              " 'And',\n",
              " 'see',\n",
              " 'thy',\n",
              " 'blood',\n",
              " 'warm',\n",
              " 'when',\n",
              " 'thou',\n",
              " \"feel'st\",\n",
              " 'it',\n",
              " 'cold.']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "test_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ec65575",
      "metadata": {
        "id": "7ec65575",
        "outputId": "645a9428-2ce8-4655-9853-77ed3c748cb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['forty', 'When'], 'winters'),\n",
              " (['winters', 'forty'], 'shall'),\n",
              " (['shall', 'winters'], 'besiege'),\n",
              " (['besiege', 'shall'], 'thy'),\n",
              " (['thy', 'besiege'], 'brow,'),\n",
              " (['brow,', 'thy'], 'And'),\n",
              " (['And', 'brow,'], 'dig'),\n",
              " (['dig', 'And'], 'deep'),\n",
              " (['deep', 'dig'], 'trenches'),\n",
              " (['trenches', 'deep'], 'in'),\n",
              " (['in', 'trenches'], 'thy'),\n",
              " (['thy', 'in'], \"beauty's\"),\n",
              " ([\"beauty's\", 'thy'], 'field,'),\n",
              " (['field,', \"beauty's\"], 'Thy'),\n",
              " (['Thy', 'field,'], \"youth's\"),\n",
              " ([\"youth's\", 'Thy'], 'proud'),\n",
              " (['proud', \"youth's\"], 'livery'),\n",
              " (['livery', 'proud'], 'so'),\n",
              " (['so', 'livery'], 'gazed'),\n",
              " (['gazed', 'so'], 'on'),\n",
              " (['on', 'gazed'], 'now,'),\n",
              " (['now,', 'on'], 'Will'),\n",
              " (['Will', 'now,'], 'be'),\n",
              " (['be', 'Will'], 'a'),\n",
              " (['a', 'be'], \"totter'd\"),\n",
              " ([\"totter'd\", 'a'], 'weed'),\n",
              " (['weed', \"totter'd\"], 'of'),\n",
              " (['of', 'weed'], 'small'),\n",
              " (['small', 'of'], 'worth'),\n",
              " (['worth', 'small'], 'held:'),\n",
              " (['held:', 'worth'], 'Then'),\n",
              " (['Then', 'held:'], 'being'),\n",
              " (['being', 'Then'], 'asked,'),\n",
              " (['asked,', 'being'], 'where'),\n",
              " (['where', 'asked,'], 'all'),\n",
              " (['all', 'where'], 'thy'),\n",
              " (['thy', 'all'], 'beauty'),\n",
              " (['beauty', 'thy'], 'lies,'),\n",
              " (['lies,', 'beauty'], 'Where'),\n",
              " (['Where', 'lies,'], 'all'),\n",
              " (['all', 'Where'], 'the'),\n",
              " (['the', 'all'], 'treasure'),\n",
              " (['treasure', 'the'], 'of'),\n",
              " (['of', 'treasure'], 'thy'),\n",
              " (['thy', 'of'], 'lusty'),\n",
              " (['lusty', 'thy'], 'days;'),\n",
              " (['days;', 'lusty'], 'To'),\n",
              " (['To', 'days;'], 'say,'),\n",
              " (['say,', 'To'], 'within'),\n",
              " (['within', 'say,'], 'thine'),\n",
              " (['thine', 'within'], 'own'),\n",
              " (['own', 'thine'], 'deep'),\n",
              " (['deep', 'own'], 'sunken'),\n",
              " (['sunken', 'deep'], 'eyes,'),\n",
              " (['eyes,', 'sunken'], 'Were'),\n",
              " (['Were', 'eyes,'], 'an'),\n",
              " (['an', 'Were'], 'all-eating'),\n",
              " (['all-eating', 'an'], 'shame,'),\n",
              " (['shame,', 'all-eating'], 'and'),\n",
              " (['and', 'shame,'], 'thriftless'),\n",
              " (['thriftless', 'and'], 'praise.'),\n",
              " (['praise.', 'thriftless'], 'How'),\n",
              " (['How', 'praise.'], 'much'),\n",
              " (['much', 'How'], 'more'),\n",
              " (['more', 'much'], 'praise'),\n",
              " (['praise', 'more'], \"deserv'd\"),\n",
              " ([\"deserv'd\", 'praise'], 'thy'),\n",
              " (['thy', \"deserv'd\"], \"beauty's\"),\n",
              " ([\"beauty's\", 'thy'], 'use,'),\n",
              " (['use,', \"beauty's\"], 'If'),\n",
              " (['If', 'use,'], 'thou'),\n",
              " (['thou', 'If'], 'couldst'),\n",
              " (['couldst', 'thou'], 'answer'),\n",
              " (['answer', 'couldst'], \"'This\"),\n",
              " ([\"'This\", 'answer'], 'fair'),\n",
              " (['fair', \"'This\"], 'child'),\n",
              " (['child', 'fair'], 'of'),\n",
              " (['of', 'child'], 'mine'),\n",
              " (['mine', 'of'], 'Shall'),\n",
              " (['Shall', 'mine'], 'sum'),\n",
              " (['sum', 'Shall'], 'my'),\n",
              " (['my', 'sum'], 'count,'),\n",
              " (['count,', 'my'], 'and'),\n",
              " (['and', 'count,'], 'make'),\n",
              " (['make', 'and'], 'my'),\n",
              " (['my', 'make'], 'old'),\n",
              " (['old', 'my'], \"excuse,'\"),\n",
              " ([\"excuse,'\", 'old'], 'Proving'),\n",
              " (['Proving', \"excuse,'\"], 'his'),\n",
              " (['his', 'Proving'], 'beauty'),\n",
              " (['beauty', 'his'], 'by'),\n",
              " (['by', 'beauty'], 'succession'),\n",
              " (['succession', 'by'], 'thine!'),\n",
              " (['thine!', 'succession'], 'This'),\n",
              " (['This', 'thine!'], 'were'),\n",
              " (['were', 'This'], 'to'),\n",
              " (['to', 'were'], 'be'),\n",
              " (['be', 'to'], 'new'),\n",
              " (['new', 'be'], 'made'),\n",
              " (['made', 'new'], 'when'),\n",
              " (['when', 'made'], 'thou'),\n",
              " (['thou', 'when'], 'art'),\n",
              " (['art', 'thou'], 'old,'),\n",
              " (['old,', 'art'], 'And'),\n",
              " (['And', 'old,'], 'see'),\n",
              " (['see', 'And'], 'thy'),\n",
              " (['thy', 'see'], 'blood'),\n",
              " (['blood', 'thy'], 'warm'),\n",
              " (['warm', 'blood'], 'when'),\n",
              " (['when', 'warm'], 'thou'),\n",
              " (['thou', 'when'], \"feel'st\"),\n",
              " ([\"feel'st\", 'thou'], 'it'),\n",
              " (['it', \"feel'st\"], 'cold.')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "ngrams = [\n",
        "    (\n",
        "        [test_sentence[i - j - 1] for j in range(CONTEXT_SIZE)],\n",
        "        test_sentence[i]\n",
        "    )\n",
        "    for i in range(CONTEXT_SIZE, len(test_sentence))\n",
        "]\n",
        "\n",
        "ngrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5abe8b2f",
      "metadata": {
        "id": "5abe8b2f",
        "outputId": "cbe0f646-1de0-4042-d47c-9891e15a1f8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\"'This\",\n",
              " 'And',\n",
              " 'How',\n",
              " 'If',\n",
              " 'Proving',\n",
              " 'Shall',\n",
              " 'Then',\n",
              " 'This',\n",
              " 'Thy',\n",
              " 'To',\n",
              " 'Were',\n",
              " 'When',\n",
              " 'Where',\n",
              " 'Will',\n",
              " 'a',\n",
              " 'all',\n",
              " 'all-eating',\n",
              " 'an',\n",
              " 'and',\n",
              " 'answer',\n",
              " 'art',\n",
              " 'asked,',\n",
              " 'be',\n",
              " 'beauty',\n",
              " \"beauty's\",\n",
              " 'being',\n",
              " 'besiege',\n",
              " 'blood',\n",
              " 'brow,',\n",
              " 'by',\n",
              " 'child',\n",
              " 'cold.',\n",
              " 'couldst',\n",
              " 'count,',\n",
              " 'days;',\n",
              " 'deep',\n",
              " \"deserv'd\",\n",
              " 'dig',\n",
              " \"excuse,'\",\n",
              " 'eyes,',\n",
              " 'fair',\n",
              " \"feel'st\",\n",
              " 'field,',\n",
              " 'forty',\n",
              " 'gazed',\n",
              " 'held:',\n",
              " 'his',\n",
              " 'in',\n",
              " 'it',\n",
              " 'lies,',\n",
              " 'livery',\n",
              " 'lusty',\n",
              " 'made',\n",
              " 'make',\n",
              " 'mine',\n",
              " 'more',\n",
              " 'much',\n",
              " 'my',\n",
              " 'new',\n",
              " 'now,',\n",
              " 'of',\n",
              " 'old',\n",
              " 'old,',\n",
              " 'on',\n",
              " 'own',\n",
              " 'praise',\n",
              " 'praise.',\n",
              " 'proud',\n",
              " 'say,',\n",
              " 'see',\n",
              " 'shall',\n",
              " 'shame,',\n",
              " 'small',\n",
              " 'so',\n",
              " 'succession',\n",
              " 'sum',\n",
              " 'sunken',\n",
              " 'the',\n",
              " 'thine',\n",
              " 'thine!',\n",
              " 'thou',\n",
              " 'thriftless',\n",
              " 'thy',\n",
              " 'to',\n",
              " \"totter'd\",\n",
              " 'treasure',\n",
              " 'trenches',\n",
              " 'use,',\n",
              " 'warm',\n",
              " 'weed',\n",
              " 'were',\n",
              " 'when',\n",
              " 'where',\n",
              " 'winters',\n",
              " 'within',\n",
              " 'worth',\n",
              " \"youth's\"}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "vocab = set(test_sentence)\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "505d6f4f",
      "metadata": {
        "id": "505d6f4f",
        "outputId": "fcc39984-43e3-46a2-efeb-01561bc2a841",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'This': 0,\n",
              " 'much': 1,\n",
              " 'on': 2,\n",
              " 'thine!': 3,\n",
              " 'thou': 4,\n",
              " 'held:': 5,\n",
              " 'If': 6,\n",
              " 'weed': 7,\n",
              " 'beauty': 8,\n",
              " 'an': 9,\n",
              " 'make': 10,\n",
              " 'field,': 11,\n",
              " 'succession': 12,\n",
              " 'thriftless': 13,\n",
              " 'worth': 14,\n",
              " 'trenches': 15,\n",
              " 'own': 16,\n",
              " 'thine': 17,\n",
              " 'in': 18,\n",
              " 'and': 19,\n",
              " 'all': 20,\n",
              " 'count,': 21,\n",
              " 'Thy': 22,\n",
              " \"beauty's\": 23,\n",
              " 'where': 24,\n",
              " 'deep': 25,\n",
              " 'asked,': 26,\n",
              " 'Were': 27,\n",
              " 'sum': 28,\n",
              " \"'This\": 29,\n",
              " 'lusty': 30,\n",
              " 'mine': 31,\n",
              " \"feel'st\": 32,\n",
              " 'it': 33,\n",
              " 'Shall': 34,\n",
              " 'Where': 35,\n",
              " 'made': 36,\n",
              " 'cold.': 37,\n",
              " 'child': 38,\n",
              " 'answer': 39,\n",
              " 'besiege': 40,\n",
              " 'to': 41,\n",
              " 'livery': 42,\n",
              " 'Proving': 43,\n",
              " 'Then': 44,\n",
              " 'by': 45,\n",
              " 'being': 46,\n",
              " 'praise': 47,\n",
              " 'treasure': 48,\n",
              " 'use,': 49,\n",
              " 'see': 50,\n",
              " 'And': 51,\n",
              " 'small': 52,\n",
              " 'shame,': 53,\n",
              " 'forty': 54,\n",
              " 'days;': 55,\n",
              " 'winters': 56,\n",
              " 'all-eating': 57,\n",
              " 'eyes,': 58,\n",
              " 'my': 59,\n",
              " 'when': 60,\n",
              " 'brow,': 61,\n",
              " \"youth's\": 62,\n",
              " 'couldst': 63,\n",
              " 'praise.': 64,\n",
              " 'Will': 65,\n",
              " 'fair': 66,\n",
              " 'To': 67,\n",
              " 'lies,': 68,\n",
              " 'How': 69,\n",
              " 'thy': 70,\n",
              " 'old': 71,\n",
              " 'be': 72,\n",
              " 'within': 73,\n",
              " 'his': 74,\n",
              " 'say,': 75,\n",
              " \"totter'd\": 76,\n",
              " 'blood': 77,\n",
              " 'more': 78,\n",
              " 'shall': 79,\n",
              " 'gazed': 80,\n",
              " 'proud': 81,\n",
              " 'dig': 82,\n",
              " \"deserv'd\": 83,\n",
              " 'of': 84,\n",
              " 'old,': 85,\n",
              " \"excuse,'\": 86,\n",
              " 'new': 87,\n",
              " 'When': 88,\n",
              " 'art': 89,\n",
              " 'now,': 90,\n",
              " 'the': 91,\n",
              " 'were': 92,\n",
              " 'so': 93,\n",
              " 'sunken': 94,\n",
              " 'a': 95,\n",
              " 'warm': 96}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "word_to_ix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77ba0244",
      "metadata": {
        "id": "77ba0244"
      },
      "outputs": [],
      "source": [
        "class NGramLanguageModeler(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
        "        super(NGramLanguageModeler, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
        "        self.linear2 = nn.Linear(128, vocab_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = self.embeddings(inputs).view((1, -1))\n",
        "        out = F.relu(self.linear1(embeds))\n",
        "        out = self.linear2(out)\n",
        "        log_probs = F.log_softmax(out, dim=1)\n",
        "        return log_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b618925",
      "metadata": {
        "id": "9b618925"
      },
      "outputs": [],
      "source": [
        "losses = []\n",
        "loss_function = nn.NLLLoss()\n",
        "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ddeb259",
      "metadata": {
        "id": "9ddeb259",
        "outputId": "54c424c4-d31e-41c0-bd80-38779cc29dd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[521.5907504558563, 519.1025950908661, 516.6299440860748, 514.1736812591553, 511.7308552265167, 509.30059480667114, 506.88173270225525, 504.4736969470978, 502.07710313796997, 499.6898684501648, 497.31252431869507, 494.94384121894836, 492.5830092430115, 490.22913002967834, 487.88218688964844, 485.5404107570648, 483.2023570537567, 480.8691072463989, 478.5382821559906, 476.20898938179016, 473.882116317749, 471.556667804718, 469.23264169692993, 466.9091286659241, 464.5848286151886, 462.2585201263428, 459.9307208061218, 457.6008200645447, 455.2685670852661, 452.9346661567688, 450.5985515117645, 448.25821471214294, 445.9134647846222, 443.5656020641327, 441.21330761909485, 438.8544807434082, 436.49055576324463, 434.1190792322159, 431.74177956581116, 429.3565707206726, 426.96392488479614, 424.56172811985016, 422.15298092365265, 419.73607301712036, 417.30966424942017, 414.875079035759, 412.4304469823837, 409.97597229480743, 407.5088268518448, 405.0322141647339, 402.5434663295746, 400.0426104068756, 397.52995455265045, 395.00585067272186, 392.46762096881866, 389.9181377887726, 387.3560987710953, 384.7825028896332, 382.1970454454422, 379.59804248809814, 376.9887707233429, 374.3673357963562, 371.73428869247437, 369.08967888355255, 366.4330449104309, 363.76197504997253, 361.0782200098038, 358.3821710348129, 355.6737630367279, 352.95701813697815, 350.22838747501373, 347.4910236597061, 344.74258267879486, 341.9839313030243, 339.21634697914124, 336.4375869631767, 333.64942729473114, 330.85201692581177, 328.0474315881729, 325.2345415353775, 322.41883635520935, 319.59374165534973, 316.7642553448677, 313.92634642124176, 311.08072251081467, 308.23182368278503, 305.37821167707443, 302.5203011035919, 299.65730756521225, 296.7902286052704, 293.91915822029114, 291.04725009202957, 288.17228984832764, 285.29522439837456, 282.41461113095284, 279.5364182293415, 276.6545091867447, 273.7744068801403, 270.89479780197144, 268.01749631762505]\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(100):\n",
        "    total_loss = 0\n",
        "    for context, targets in ngrams:\n",
        "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
        "        model.zero_grad()\n",
        "        log_probs = model(context_idxs)\n",
        "        loss = loss_function(log_probs, torch.tensor([word_to_ix[targets]], dtype=torch.long))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    losses.append(total_loss)\n",
        "print(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55dc79ea",
      "metadata": {
        "id": "55dc79ea",
        "outputId": "5739b68c-4ea0-4d93-c2a0-8cada8409bac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.3974, -0.8213, -0.9506,  1.1082,  0.6263,  0.2079, -2.6301,  0.8581,\n",
            "        -2.1351, -0.6569], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(model.embeddings.weight[word_to_ix[\"beauty\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b71ab868",
      "metadata": {
        "id": "b71ab868"
      },
      "outputs": [],
      "source": [
        "def make_context_vector(context, word_to_ix):\n",
        "    idxs = [word_to_ix[w] for w in context]\n",
        "    return torch.tensor(idxs, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54ab5204",
      "metadata": {
        "id": "54ab5204"
      },
      "outputs": [],
      "source": [
        "CONTEXT_SIZE = 2\n",
        "EMDEDDING_DIM = 100\n",
        "\n",
        "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
        "Computational processes are abstract beings that inhabit computers.\n",
        "As they evolve, processes manipulate other abstract things called data.\n",
        "The evolution of a process is directed by a pattern of rules\n",
        "called a program. People create programs to direct processes. In effect,\n",
        "we conjure the spirits of the computer with our spells.\"\"\".split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "838a82f6",
      "metadata": {
        "id": "838a82f6"
      },
      "outputs": [],
      "source": [
        "vocab = set(raw_text)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "word_to_ix = {word:ix for ix, word in enumerate(vocab)}\n",
        "ix_to_word = {ix:word for ix, word in enumerate(vocab)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df16f720",
      "metadata": {
        "id": "df16f720",
        "outputId": "45306d89-aff0-45bb-e275-333fbb25dfb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['We', 'are', 'to', 'study'], 'about')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "data = []\n",
        "for i in range(2, len(raw_text) - 2):\n",
        "    context = [raw_text[i - 2], raw_text[i - 1],\n",
        "               raw_text[i + 1], raw_text[i + 2]]\n",
        "    target = raw_text[i]\n",
        "    data.append((context, target))\n",
        "data[:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93ce870f",
      "metadata": {
        "id": "93ce870f"
      },
      "outputs": [],
      "source": [
        "class CBOW(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(CBOW, self).__init__()\n",
        "\n",
        "        #out: 1 x emdedding_dim\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear1 = nn.Linear(embedding_dim, 128)\n",
        "        self.activation_function1 = nn.ReLU()\n",
        "\n",
        "        #out: 1 x vocab_size\n",
        "        self.linear2 = nn.Linear(128, vocab_size)\n",
        "        self.activation_function2 = nn.LogSoftmax(dim = -1)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = sum(self.embeddings(inputs)).view(1,-1)\n",
        "        out = self.linear1(embeds)\n",
        "        out = self.activation_function1(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.activation_function2(out)\n",
        "        return out\n",
        "\n",
        "    def get_word_emdedding(self, word):\n",
        "        word = torch.tensor([word_to_ix[word]])\n",
        "        return self.embeddings(word).view(1,-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcdd9e85",
      "metadata": {
        "id": "dcdd9e85"
      },
      "outputs": [],
      "source": [
        "model = CBOW(vocab_size, EMDEDDING_DIM)\n",
        "\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "438ef9c8",
      "metadata": {
        "id": "438ef9c8"
      },
      "outputs": [],
      "source": [
        "for epoch in range(50):\n",
        "    total_loss = 0\n",
        "\n",
        "    for context, target in data:\n",
        "        context_vector = make_context_vector(context, word_to_ix)\n",
        "\n",
        "        log_probs = model(context_vector)\n",
        "\n",
        "        total_loss += loss_function(log_probs, torch.tensor([word_to_ix[target]]))\n",
        "\n",
        "    #optimize at the end of each epoch\n",
        "    optimizer.zero_grad()\n",
        "    total_loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7481166a",
      "metadata": {
        "id": "7481166a"
      },
      "outputs": [],
      "source": [
        "#TESTING\n",
        "context = ['People','create','to', 'direct']\n",
        "context_vector = make_context_vector(context, word_to_ix)\n",
        "a = model(context_vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8046b585",
      "metadata": {
        "id": "8046b585",
        "outputId": "b46b8753-b63b-48ea-a971-4b437c0c739a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw text: We are about to study the idea of a computational process. Computational processes are abstract beings that inhabit computers. As they evolve, processes manipulate other abstract things called data. The evolution of a process is directed by a pattern of rules called a program. People create programs to direct processes. In effect, we conjure the spirits of the computer with our spells.\n",
            "\n",
            "Context: ['People', 'create', 'to', 'direct']\n",
            "\n",
            "Prediction: programs\n"
          ]
        }
      ],
      "source": [
        "#Print result\n",
        "print(f'Raw text: {\" \".join(raw_text)}\\n')\n",
        "print(f'Context: {context}\\n')\n",
        "print(f'Prediction: {ix_to_word[torch.argmax(a[0]).item()]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e2b3683",
      "metadata": {
        "id": "0e2b3683"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}